{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "boolean-branch",
   "metadata": {},
   "source": [
    "# Aluno: Guilherme Cristiano Goll\n",
    "\n",
    "Exercício de classificação de texto, com aplicação de técnicas para normalização (tokenização, bag of words, stematização, etc).\n",
    "\n",
    "Ao final é apresentada a conclusão sobre os resultados obtidos após a execução do classificador com Regressão Logística e o SIA (Sentiment Intensity Analyzer) do NLKT.\n",
    "\n",
    "Observação: parte da limpeza do dataset (csv) foi realizada através de ferramenta externa, para facilitar a importação do arquivo no notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "complicated-reasoning",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "rotary-peeing",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('.\\\\imdb.csv', sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "blocked-screw",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [review, sentiment]\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.head()\n",
    "df[df.sentiment.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "returning-glenn",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review       0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentiment.value_counts()\n",
    "df[df.review == ''].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "distant-reviewer",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\guilh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\guilh\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "signal-thesaurus",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_df(df):\n",
    "    '''Normalize dataframe, applying tokenization and other techniques\n",
    "    '''\n",
    "    ps = PorterStemmer()\n",
    "    \n",
    "    stop_words=set(stopwords.words(\"english\"))\n",
    "    \n",
    "    def normalize(text: str):        \n",
    "        final_sent = []\n",
    "        tokenized_sent = sent_tokenize(text.strip())\n",
    "        for sent in tokenized_sent:\n",
    "            tokenized_words = word_tokenize(sent)\n",
    "            for word in tokenized_words:\n",
    "                if word not in stop_words:\n",
    "                    stemmed_word = ps.stem(word)\n",
    "                    final_sent.append(' ' + stemmed_word)\n",
    "        \n",
    "        return ''.join(final_sent)\n",
    "    \n",
    "    for idx in range(len(df)):\n",
    "        df.iat[idx, 0] = normalize(df.iloc[idx, 0])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "according-duration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one review mention watch 1 Oz episod 'll hook...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonder littl product . the film techniqu un...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought wonder way spend time hot summer we...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basic 's famili littl boy ( jake ) think 's z...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei 's love time money visual stun ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0   one review mention watch 1 Oz episod 'll hook...  positive\n",
       "1   A wonder littl product . the film techniqu un...  positive\n",
       "2   I thought wonder way spend time hot summer we...  positive\n",
       "3   basic 's famili littl boy ( jake ) think 's z...  negative\n",
       "4   petter mattei 's love time money visual stun ...  positive"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = normalize_df(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moving-financing",
   "metadata": {},
   "source": [
    "# Classificador com Regressão Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "pretty-exercise",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divisão das variáveis preditoras e variáveis preditas\n",
    "X = df['review']\n",
    "y = df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "elegant-label",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criação do bag of words\n",
    "vectorizer = CountVectorizer(tokenizer=lambda doc: doc, lowercase=False)\n",
    "X = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "historic-monitoring",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divisão do dataset entre treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "warming-label",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.ravel()\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(C=1,\n",
    "                           solver='saga',\n",
    "                           penalty='elasticnet',\n",
    "                           l1_ratio=0.2,\n",
    "                           class_weight='balanced',\n",
    "                           max_iter=6000,\n",
    "                           dual=False)\n",
    "model = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "novel-liver",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6584"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Apuração da acurácia do modelo\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electrical-humor",
   "metadata": {},
   "source": [
    "# Classificador Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "lesser-aging",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "cv = CountVectorizer(lowercase=True,stop_words='english',ngram_range = (1,1),tokenizer = token.tokenize)\n",
    "text_counts= cv.fit_transform(df['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "quarterly-settlement",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    text_counts, df['sentiment'], test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "brave-hungarian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8498"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "average-calendar",
   "metadata": {},
   "source": [
    "# Predição com SIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aboriginal-condition",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[['review']], df[['sentiment']], stratify=df['sentiment'], test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "toxic-drink",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sia_predict(sia: SentimentIntensityAnalyzer, tx: str) -> int:\n",
    "    return 'positive' if sia.polarity_scores(tx)[\"compound\"] > 0 else 'negative'\n",
    "\n",
    "sia_y_pred = []\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "for i, tx in enumerate(X_test.review):\n",
    "    sia_y_pred.append(sia_predict(sia, tx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "raising-breast",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(sia_y_pred[6] == y_test.iloc[6][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "considered-conditioning",
   "metadata": {},
   "outputs": [],
   "source": [
    "verdadeiro_positivo = 0\n",
    "verdadeiro_negativo = 0\n",
    "for i in range(len(y_test)):\n",
    "    answer = y_test.iloc[i][0]\n",
    "    if answer == sia_y_pred[i]:\n",
    "        if answer == 'positive':\n",
    "            verdadeiro_positivo += 1\n",
    "        elif answer == 'negative':\n",
    "            verdadeiro_negativo += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "optimum-spirit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de verdadeiros positivos: 6215/7500 = 82.87%\n",
      "Total de verdadeiros negativos: 3575/7500 = 47.67%\n",
      "Acurárcia geral: 65.27%\n"
     ]
    }
   ],
   "source": [
    "total_positivo = y_test[y_test == 'positive'].count()[0]\n",
    "total_negativo = y_test[y_test == 'negative'].count()[0]\n",
    "print(f'Total de verdadeiros positivos: {verdadeiro_positivo}/{total_positivo} = {(verdadeiro_positivo/total_positivo) * 100 :.2f}%')\n",
    "print(f'Total de verdadeiros negativos: {verdadeiro_negativo}/{total_negativo} = {(verdadeiro_negativo/total_negativo) * 100 :.2f}%')\n",
    "print(f'Acurárcia geral: {(verdadeiro_positivo + verdadeiro_negativo) / len(y_test) * 100 :.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-garage",
   "metadata": {},
   "source": [
    "# Conclusão\n",
    "\n",
    "A execução da Regressão Logística x SIA retornaram resultados bastante semelhantes em termos de acurácia: 65,84%, contra 65,27%, respectivamente. Porém, vale ressaltar que não foram exploradas todas as técnicas de pré-processamento dos dados, como Lematização, por exemplo. Neste sentido, acredito que ao trabalhar de uma forma mais profunda na etapa de normalização, deve ser possível obter melhores resultados.\n",
    "\n",
    "Por curiosidade, foi aplicado ainda a classificação com o algoritmo Naive Bayes Multinomial, que apresentou um resultado consideravalmente superior em termos de acurácia: 84,98%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
